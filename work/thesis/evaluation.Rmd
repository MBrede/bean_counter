# Evaluation

Im folgenden Kapitel wird die durchgeführte Überprüfung der Umsetzung beschrieben. 
Dazu wird zuerst auf den Prozess der Rücksprachen und Tests mit und durch die Mitarbeitenden des Instituts für Materialphysik und die dabei entstandenen Testergebnisse eingegangen, darauf folgen die Ergebnisse des Versuchs, bestehende, händisch generierte Kornverteilungen möglichst gut durch die implementierten Methoden nachzuvollziehen.

## Praxistest

Während des Entwicklungs-Prozesses des Tools wurden an insgesamt 8 Terminen Video-Calls mit Mitarbeitenden der Uni Göttingen durchgeführt. In diesen Calls wurden regelmäßig der Stand des Tools präsentiert und weitere Schritte besprochen. Neben den Calls wurden asynchron Tests durchgeführt und Änderungswünsche und Bugreports über Github Issues gesammelt.
Über diesen Entwicklungsprozess wurde sichergestellt, dass alle Design-Anforderungen an die Bedienmöglichkeiten und oberflächlichen Eigenschaften des Tools erfüllt sind. So wurde während dieses Prozesses die Auswahl an Vorverarbeitungsschritten festgelegt, die möglichst gute Darstellung bisheriger und gefundener Ergebnisse diskutiert und eine Reihe von Anpassungen zur Verbesserung der Nutzbarkeit wie eine höhere Verbosität bei Speichern und laden und ein Fortschrittsbalken während laufender Auswertungen hinzugefügt.
Nachdem das Tool so weit fertig gestellt war, dass erste manuelle Tests zu vielversprechenden Korngrößen-Verteilungen führten, wurde am 18.5.2022 eine weitere Evaluationsrunde angestoßen. Dazu wurde zwei Studierenden des Instituts das Tool präsentiert und sein Nutzung erklärt - verbunden mit der Bitte es für ihre Auswertung auszutesten. Von den zwei instruierten Studierenden brach einer kurz nach dem Gespräch unabhängig vom Tool seine Abschlussarbeit ab, wodurch der praxisnahe Anwendungstest nur von einer Person durchgeführt wurde. Am 27.5. berichtete diese Testperson, dass die Auswertung mit DBSCAN bei ihren Bildern zu keinem befriedigenden Ergebnis führte. Daraufhin wurde das Tool nach Konsultation mit der Betreuung der Person in Anlehnung an @stutzSuperpixelsEvaluationStateoftheart2018 und die dort gezeigten Muster der Superpixel um `Normalized Cuts` und `SLIC` erweitert.
Am 6.6. berichtete die Testperson, dass sie ihre Bilder erfolgreich mit SLIC auswerten konnte - die Verteilungen seien oberflächlich vergleichbar mit den per Linienschnitt generierten. 
Weiterhin wurde berichtet, dass die Anpassung des ersten Bildes eines Stapels wegen der Suche von passenden Vorverarbeitungs- und Auswertungseinstellungen etwa 5 Minuten länger gedauert habe, als die Auswertung per Linienschnitt. Bei jedem weiteren Bild von ähnlichem Material sei die Auswertung mit dem Tool aber pro Bild etwa 25 Minuten schneller gewesen.

Die Ergebnisse dieses Feldversuchs können als vorsichtige Belege für die Erfüllung von einer Reihe von Anforderungen an das Tool gesehen werden:

1. die Ergebnisse sahen laut Aussage der Testperson ähnlich zu den händisch generierten Kornverteilungen aus.
2. die Auswertung ist ab dem 2. Bild ohne Empfehlungen für Voreinstellungen schneller als die per Linienschnitt.
3. durch die Notwendigkeit der Erweiterung um Normalized Cuts und SLIC konnte die einfache Erweiterbarkeit getestet werden, die weitere Funktionalität konnte reibungslos aufgenommen werden.

## Technische Evaluation

Für die Überprüfung der Validität der ausgewählten Superpixel-Methoden wurde versucht, für jedes zur Verfügung stehende Bild und jede implementierte Auswertungsmethode ein Set an Einstellungen zu finden, dass die generierte Kornverteilung möglichst nah an per Linienschnitt ausgemessene Verteilung der Korngrößen bringt.
Dazu wurde mit Hilfe des `HPBandster`-Moduls [@HpBandSter2022] versucht, möglichst optimale Einstellungen zu finden, die zu Auswertungsergebnissen mit der minimalen Kolmogorov-Smirnov Teststatistik beim Vergleich mit den Linienschnittergebnissen führen. Während der Masterarbeit wurde das Git-Repository des `HPBandster`-Moduls mit dem Hinweis aktualisiert, dass das Modul nicht weiter gepflegt wird - trotzdem wurden aus Gründen der Vergleichbarkeit die restlichen Tests auch mit diesem Modul durchgeführt.
Dabei ist die Wahl des Optimizers aber insofern fragwürdig, dass die Vorteile des Hyperband-Aspekts des Implementierten BOHB-Verfahrens bei der Optimierung der Analyseverfahren nicht ausgenutzt werden. Damit dieses Verfahren zu schnelleren Analyseergebnissen führt, muss ein sinnvolles Budget definiert werden können, dass weniger aufwändige Auswertungen als Indikatoren für aufwändigere Auswertungsgüten möglich macht. Da die einzige wirkliche Stellschraube zur Reduktion von Cluster-Laufzeiten die Reduktion der Anzahl der berechneten Distanzen ist und dies im gegebenen Anwendungsfall eine Reduktion der Bildgröße bedeuten würde, ist die BOHB-Optimierung nur noch mit einem reinen TPE zu vergleichen. Zwar könnte die Bildfläche vor dem Anpassen reduziert werden, diese Lösung würde zum Beispiel bei SLIC aber auch zu weniger Cluster-Zentren bei der optimalen Lösung führen. Dadurch würde die Hyperband-Optimierung bei niedrigerem Budget zu aktiver Verschlechterung der Zielfunktions-Schätzung für das gesamte Budget bedeuten.
Der Parameterraum des Optimierungsversuchs aller drei Analysemethoden bestand dabei aus den Filtern und ihren Einstellungen, die Reihenfolge der Filter und der Argumente der Analysemethoden. Die Grenzen und Auflösungen der Parameterräume wurden dabei so festgelegt, wie sie nach den händischen Tests sinnvoll erschienen. Nach einem kleinen Test wurde bei Boden- und Deckeneffekten entsprechend der Parameterraum angepasst.

In Abb. \@ref(fig:evaluation) ist das Ergebnis der drei Optimierungen zu sehen - die Einstellungen und die Vorverarbeitung jeden Verfahrens wurden dabei in 100 Durchläufen optimiert. 
Es ist deutlich zu erkennen, dass SLIC und DBSCAN mit Abstand besser abgeschnitten haben, als Normalized Cuts. Außerdem entsteht der Eindruck, dass SLIC und DBSCAN als ergänzende Ansätze zu verstehen sind - die die Aufnahmen verbindenen Linien kreuzen sich. Bilder, die schlechter mit SLIC auszuwerten waren wurden also besser mit DBSCAN ausgewertet.

(ref:evaluationSubCap) Ergebnisse der Bayes-Optimierung.

(ref:evaluationCap) Ergebnisse der Bayes-Optimierung. Die TPE wurden für jedes Bild auf die $D$-Statistik zwischen der generierten und der händisch gemessenen Kornverteilung optimiert. Der Wert kann normalerweise zwischen 0 und 1 liegen, wurde aber auf 1.5 gesetzt, wenn keine Lösung zu finden war. Dies war insbesondere dann der Fall, wenn bei den Normalized Cuts keine sinnvolle Lösung gefunden werden konnte. Die grauen Linien verbinden die Loss-Werte in den drei Bedingungen pro Bild.

```{r evaluation, echo = F, fig.cap='(ref:evaluationCap)', fig.align='center',out.width=paste0(.96/1,'\\textwidth'), fig.show='hold', fig.scap='(ref:evaluationSubCap)'}
df <- map_dfr(list.files(path = 'data/', pattern = '100.csv', full.names = T),
        ~read_csv(.)) %>% 
  mutate(analysis = case_when(!is.na(SLIC.n_segments) ~ 'SLIC',
                              !is.na(ncuts.thresh) ~ 'Normalized Cuts',
                              T ~ 'DBSCAN'),
         analysis = factor(analysis, levels = c('SLIC', 'DBSCAN', 'Normalized Cuts')),
         file = str_sub(file, 1, -5),
         file = str_remove(file, '_(ncuts|slic)'))
df %>%  
  select(loss, analysis, file) %>%
  ggplot(aes(x = analysis, y = loss)) +
  geom_boxplot() +
  geom_line(aes(x = as.numeric(analysis), group = file),
            alpha = .1) +
  geom_point(aes(x = as.numeric(analysis), group = file),
            alpha = .1,
             size = .4) +
  theme_minimal() +
  labs(x = '', y = 'D')
```

Um die vielversprechenden Ergebnisse für SLIC und DBSCAN zu verdeutlichen, wurde je ein zweiter Optimierungsversuch gestartet, diesmal mit je 500 Optimierungsdurchläufen (Abb. \@ref(fig:evaluation500) ). Das Ergebnis bestätigt den Eindruck aus dem ersten Test, die beiden Methoden scheinen zum Einen 

\@ref(fig:evaluation500) 

(ref:evaluation500SubCap) Ergebnis von 500 Optimierungsdurchläufen für SLIC und DBSCAN.

(ref:evaluation500Cap) Ergebnis von 500 Optimierungsdurchläufen für SLIC und DBSCAN. Hier steht eine Bildbeschriftung

```{r evaluation500, echo = F, fig.cap='(ref:evaluation500Cap)', fig.align='center',out.width=paste0(.96/1,'\\textwidth'), fig.show='hold', fig.scap='(ref:evaluation500SubCap)'}
df <- map_dfr(list.files(path = 'data/', pattern = '500.csv', full.names = T),
        ~read_csv(.)) %>% 
  mutate(analysis = case_when(!is.na(SLIC.n_segments) ~ 'SLIC',
                              T ~ 'DBSCAN'),
         analysis = factor(analysis, levels = c('SLIC', 'DBSCAN')),
         file = str_sub(file, 1, -5),
         file = str_remove(file, '_(ncuts|slic)'))
df %>%  
  select(loss, analysis, file) %>%
  ggplot(aes(x = analysis, y = loss)) +
  geom_boxplot() +
  geom_line(aes(x = as.numeric(analysis), group = file),
            alpha = .1) +
  geom_point(aes(x = as.numeric(analysis), group = file),
            alpha = .1,
             size = .4) +
  theme_minimal() +
  labs(x = '', y = 'D')
```

Als weiteren Aspekt kann anhand der Optimierungsergebnisse überprüft werden, ob die optimalen Einstellungen der Vorverarbeitung Methoden-Unabhängig sind. Sollte dies so sein, sollten die Optimierungsversuche bei SLIC und DBSCAN zu ähnlichen Ergebnissen pro Bild gekommen sein. 

In Abb. \@ref(fig:evalCor) sind die Zusammenhänge aller optimierter Vorverarbeitungs-Schritte dargestellt. Es ist kein Zusammenhang bei keinem der Parameter ersichtlich, die Vorverarbeitung scheint also Analyse-spezifisch angepasst werden zu müssen.

(ref:evalCorSubCap) Scatterplots und Korrelationen der Vorverabeitungseinstellungen.

(ref:evalCorCap) Scatterplots und Korrelationen der Vorverabeitungseinstellungen. Eine Unabhängigkeit der optimalen Einstellungen von den Analyseverfahren sollte zu hohen Korrelationen und annähernd diagonalen Punktwolken führen.

```{r evalCor, echo = F, fig.cap='(ref:evalCorCap)', fig.align='center',out.width=paste0(.96/1,'\\textwidth'), fig.show='hold', fig.scap='(ref:evalCorSubCap)'}
df %>% 
  select(which(sapply(df, \(x)!any(is.na(x))))) %>% 
  select(file, analysis, gauss.k: sav.window) %>% 
  pivot_longer(-1:-2,
               names_to = 'prep_hyper') %>% 
  pivot_wider(names_from = analysis) %>% 
  ggplot(aes(x = DBSCAN, y = SLIC)) +
  geom_point() +
  facet_wrap(~prep_hyper, scales = 'free')
```


