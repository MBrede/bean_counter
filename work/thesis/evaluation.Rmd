# Evaluation

Im folgenden Kapitel wird die durchgeführte Überprüfung der Umsetzung beschrieben. 
Dazu wird zuerst auf den Prozess der Rücksprachen und Tests mit und durch die Mitarbeitenden des Instituts für Materialphysik und die dabei entstandenen Testergebnisse eingegangen, darauf folgen die Ergebnisse des Versuchs, bestehende, händisch generierte Kornverteilungen möglichst gut durch die implementierten Methoden nachzuvollziehen.

## Praxistest

Während des Entwicklungs-Prozesses des Tools wurden an insgesamt 8 Terminen Video-Calls mit Mitarbeitenden der Uni Göttingen durchgeführt. In diesen Treffen wurden regelmäßig der Stand des Tools präsentiert und weitere Schritte besprochen. Neben den Treffen wurden asynchron Tests durchgeführt und Änderungswünsche und Bugreports über Github Issues gesammelt.
Über diesen Entwicklungsprozess wurde sichergestellt, dass alle Design-Anforderungen an die Bedienmöglichkeiten und oberflächlichen Eigenschaften des Tools erfüllt sind. So wurde während dieses Prozesses die Auswahl an Vorverarbeitungsschritten festgelegt, die möglichst gute Darstellung bisheriger und gefundener Ergebnisse diskutiert und eine Reihe von Anpassungen zur Verbesserung der Nutzbarkeit wie eine höhere Verbosität bei Speichern und Laden und ein Fortschrittsbalken während laufender Auswertungen hinzugefügt.
Nachdem das Tool so weit fertig gestellt war, dass erste manuelle Tests zu vielversprechenden Korngrößen-Verteilungen führten, wurde am 18.5.2022 eine weitere Evaluationsrunde angestoßen. Dazu wurde zwei Studierenden des Instituts das Tool präsentiert und seine Nutzung erklärt - verbunden mit der Bitte, es für ihre Auswertung auszutesten. Von den zwei instruierten Studierenden brach einer kurz nach dem Gespräch seine Abschlussarbeit ab, wodurch der praxisnahe Anwendungstest nur von einer Person durchgeführt wurde. Am 27.5. berichtete diese Testperson, dass die Auswertung mit DBSCAN bei ihren Bildern zu keinem befriedigenden Ergebnis führte. Daraufhin wurde das Tool nach Konsultation mit der Betreuung der Person in Anlehnung an @stutzSuperpixelsEvaluationStateoftheart2018 und die dort gezeigten Muster der Superpixel um `Normalized Cuts` und `SLIC` erweitert.
Am 6.6. berichtete die Testperson, dass sie ihre Bilder erfolgreich mit SLIC auswerten konnte - die Verteilungen seien oberflächlich vergleichbar mit den per Linienschnitt generierten. 
Weiterhin wurde berichtet, dass die Anpassung des ersten Bildes eines Stapels wegen der Suche von passenden Vorverarbeitungs- und Auswertungseinstellungen etwa 5 Minuten länger gedauert habe, als die Auswertung per Linienschnitt. Bei jedem weiteren Bild von ähnlichem Material sei die Auswertung mit dem Tool aber pro Bild etwa 25 Minuten schneller gewesen.

Die Ergebnisse dieses Feldversuchs können als vorsichtige Belege für die Erfüllung einer Reihe von Anforderungen an das Tool gesehen werden:

1. die Ergebnisse sahen laut Aussage der Testperson ähnlich zu den händisch generierten Kornverteilungen aus.
2. die Auswertung ist ab dem 2. Bild ohne Empfehlungen für Voreinstellungen schneller als die per Linienschnitt.
3. durch die Notwendigkeit der Erweiterung um Normalized Cuts und SLIC konnte die einfache Erweiterbarkeit getestet werden, die weitere Funktionalität konnte reibungslos aufgenommen werden.

## Technische Evaluation

Für die Überprüfung der Validität der ausgewählten Superpixel-Methoden wurde versucht, für jedes zur Verfügung stehende Bild und jede implementierte Auswertungsmethode ein Set an Einstellungen zu finden, das die generierte Kornverteilung möglichst nah an per Linienschnitt ausgemessene Verteilung der Korngrößen bringt.
Dazu wurde mit Hilfe des `HPBandster`-Moduls [@HpBandSter2022] versucht, möglichst optimale Einstellungen zu finden, die zu Auswertungsergebnissen mit der minimalen Kolmogorov-Smirnov Teststatistik beim Vergleich mit den Linienschnittergebnissen führen. Während der Masterarbeit wurde das Git-Repository des `HPBandster`-Moduls mit dem Hinweis aktualisiert, dass das Modul nicht weiter gepflegt wird - trotzdem wurden aus Gründen der Vergleichbarkeit die restlichen Tests auch mit diesem Modul durchgeführt.
Dabei ist die Wahl des Optimizers aber insofern fragwürdig, da die Vorteile des Hyperband-Aspekts des Implementierten BOHB-Verfahrens bei der Optimierung der Analyseverfahren nicht ausgenutzt werden. Damit dieses Verfahren zu schnelleren Analyseergebnissen führt, muss ein sinnvolles Budget definiert werden können, das weniger aufwändige Auswertungen als Indikatoren für aufwändigere Auswertungsgüten möglich macht. Da die einzige wirkliche Stellschraube zur Reduktion von Cluster-Laufzeiten die Reduktion der Anzahl der berechneten Distanzen ist und dies im gegebenen Anwendungsfall eine Reduktion der Bildgröße bedeuten würde, ist die BOHB-Optimierung nur noch mit einem reinen TPE zu vergleichen. Zwar könnte die Bildfläche vor dem Anpassen reduziert werden, diese Lösung würde zum Beispiel bei SLIC aber auch zu weniger Cluster-Zentren bei der optimalen Lösung führen. Dadurch würde die Hyperband-Optimierung bei niedrigerem Budget zu aktiver Verschlechterung der Zielfunktions-Schätzung für das gesamte Budget bedeuten.
Der Parameterraum des Optimierungsversuchs aller drei Analysemethoden bestand dabei aus den Filtern und ihren Einstellungen, die Reihenfolge der Filter und der Argumente der Analysemethoden. Die Grenzen und Auflösungen der Parameterräume wurden dabei so festgelegt, wie sie nach den händischen Tests sinnvoll erschienen. Nach einem kleinen Test wurde bei Boden- und Deckeneffekten entsprechend der Parameterraum angepasst.

In Abb. \@ref(fig:evaluation) ist das Ergebnis der drei Optimierungen zu sehen - die Einstellungen und die Vorverarbeitung jeden Verfahrens wurden dabei in 100 Durchläufen optimiert. 
Es ist deutlich zu erkennen, dass SLIC und DBSCAN mit Abstand besser abgeschnitten haben als Normalized Cuts. Außerdem entsteht der Eindruck, dass SLIC und DBSCAN als ergänzende Ansätze zu verstehen sind - die die Aufnahmen verbindenen Linien kreuzen sich. Bilder, die höhere und damit schlechtere $D$-Fit-Statistiken mit SLIC ergaben, konnten also tendenziell besser mit DBSCAN ausgewertet werden und andersherum.

(ref:evaluationSubCap) Ergebnisse der Bayes-Optimierung.

(ref:evaluationCap) Ergebnisse der Bayes-Optimierung. Die TPE wurden für jedes Bild auf die $D$-Statistik zwischen der generierten und der händisch gemessenen Kornverteilung optimiert. Der Wert kann normalerweise zwischen 0 und 1 liegen, wurde aber auf 1.5 gesetzt, wenn keine Lösung zu finden war. Dies war insbesondere dann der Fall, wenn bei den Normalized Cuts keine sinnvolle Lösung gefunden werden konnte. Die grauen Linien verbinden die Loss-Werte in den drei Bedingungen pro Bild.

```{r evaluation, echo = F, fig.cap='(ref:evaluationCap)', fig.align='center',out.width=paste0(.96/1,'\\textwidth'), fig.show='hold', fig.scap='(ref:evaluationSubCap)'}
df <- map_dfr(list.files(path = 'data/', pattern = '100.csv', full.names = T),
        ~read_csv(.)) %>% 
  mutate(analysis = case_when(!is.na(SLIC.n_segments) ~ 'SLIC',
                              !is.na(ncuts.thresh) ~ 'Normalized Cuts',
                              T ~ 'DBSCAN'),
         analysis = factor(analysis, levels = c('SLIC', 'DBSCAN', 'Normalized Cuts')),
         file = str_sub(file, 1, -5),
         file = str_remove(file, '_(ncuts|slic)'))
df %>%  
  select(loss, analysis, file) %>%
  ggplot(aes(x = analysis, y = loss)) +
  geom_boxplot() +
  geom_line(aes(x = as.numeric(analysis), group = file),
            alpha = .1) +
  geom_point(aes(x = as.numeric(analysis), group = file),
            alpha = .1,
             size = .4) +
  theme_minimal() +
  labs(x = '', y = 'D')
```

Um die vielversprechenden Ergebnisse für SLIC und DBSCAN zu verdeutlichen, wurde je ein zweiter Optimierungsversuch gestartet, diesmal mit je 500 Optimierungsdurchläufen (Abb. \@ref(fig:evaluation500) ). Das Ergebnis bestätigt den Eindruck aus dem ersten Test, die beiden Methoden scheinen zum Einen ergänzend einzusetzen zu sein (die am schlechtesten angepasste Kornverteilung aus der SLIC-Optimierung konnte mit DBSCAN am besten vorhergesagt werden), zum Anderen bestätigt sich der leichte Trend aus den 100 Optimierungsdurchläufen, nach dem SLIC für die zu Verfügung stehenden Bilder ein insgesamt besseres Ergebnis erzielte. Beide Verfahren scheinen aber verlässliche Ergebnisse produzieren zu können. Auch wenn die $D$-Werte beider Verfahren bei Vergleich mit der entsprechenden Verteilung bei der Anzahl an gefundenen Körnern wahrscheinlich signifikant würden und damit auf unterschiedliche Ursprungs-Verteilungen hinwiesen - die Verteilungen nähern sich deutlich an. Unter Berücksichtigung der aus dem Linienschnitt entstehenden Fehler und dem unterschiedlichen Anteil des ausgewerteten Bildes, sind die Ergebnisse vielversprechend, benötigen aber weitere Evaluation.

\@ref(fig:evaluation500) 

(ref:evaluation500SubCap) Ergebnis von 500 Optimierungsdurchläufen für SLIC und DBSCAN.

(ref:evaluation500Cap) Ergebnis von 500 Optimierungsdurchläufen für SLIC und DBSCAN. Die grauen Linien verbinden die Loss-Werte in den zwei Bedingungen pro Bild.

```{r evaluation500, echo = F, fig.cap='(ref:evaluation500Cap)', fig.align='center',out.width=paste0(.96/1,'\\textwidth'), fig.show='hold', fig.scap='(ref:evaluation500SubCap)'}
df <- map_dfr(list.files(path = 'data/', pattern = '500.csv', full.names = T),
        ~read_csv(.)) %>% 
  mutate(analysis = case_when(!is.na(SLIC.n_segments) ~ 'SLIC',
                              T ~ 'DBSCAN'),
         analysis = factor(analysis, levels = c('SLIC', 'DBSCAN')),
         file = str_sub(file, 1, -5),
         file = str_remove(file, '_(ncuts|slic)'))
df %>%  
  select(loss, analysis, file) %>%
  ggplot(aes(x = analysis, y = loss)) +
  geom_boxplot() +
  geom_line(aes(x = as.numeric(analysis), group = file),
            alpha = .1) +
  geom_point(aes(x = as.numeric(analysis), group = file),
            alpha = .1,
             size = .4) +
  theme_minimal() +
  labs(x = '', y = 'D') +
  ylim(0,.3)
```

Als weiterer Aspekt kann anhand der Optimierungsergebnisse überprüft werden, ob die optimalen Einstellungen der Vorverarbeitung methodenunabhängig sind. Sollte dies so sein, sollten die Optimierungsversuche bei SLIC und DBSCAN zu ähnlichen Ergebnissen pro Bild gekommen sein. 

In Abb. \@ref(fig:evalCor) sind die Zusammenhänge aller optimierter Vorverarbeitungs-Schritte dargestellt. Es ist kein Zusammenhang bei keinem der Parameter ersichtlich, die Vorverarbeitung scheint also analysespezifisch angepasst werden zu müssen. Insbesondere in Anbetracht der Parametrischen Natur vom SLIC zugrundeliegenden k-Means Clustering und der Non-parametrischen Natur von DBSCAN scheint der Einfluss der Reduktion parametrischen Rauschens einleuchtend.

(ref:evalCorSubCap) Scatterplots und Korrelationen der Vorverabeitungseinstellungen.

(ref:evalCorCap) Scatterplots und Korrelationen der Vorverabeitungseinstellungen. Eine Unabhängigkeit der optimalen Einstellungen von den Analyseverfahren sollte zu hohen Korrelationen und annähernd diagonalen Punktwolken führen.

```{r evalCor, echo = F, fig.cap='(ref:evalCorCap)', fig.align='center',out.width=paste0(.96/1,'\\textwidth'), fig.show='hold', fig.scap='(ref:evalCorSubCap)'}
df %>% 
  select(which(sapply(df, \(x)!any(is.na(x))))) %>% 
  select(file, analysis, gauss.k: sav.window) %>% 
  pivot_longer(-1:-2,
               names_to = 'prep_hyper') %>% 
  pivot_wider(names_from = analysis) %>% 
  ggplot(aes(x = DBSCAN, y = SLIC)) +
  geom_point() +
  facet_wrap(~prep_hyper, scales = 'free')
```

In Abb. \@ref(fig:mostDistantImages) sind die Kornbilder zu sehen, die den größten Abstand zwischen ihrem Fit in der SLIC und der DBSCAN-Auswertung aufweisen. Das besser von SLIC ausgewertete Bild weist kleinere, regelmäßigere Körner auf, die Körner im von DBSCAN besser ausgewerteten Bild sind wesentlich unregelmäßiger in Form und Größe. Der Eindruck der Überlegenheit SLICs im Erkennen regelmäßiger, kleiner Strukturen aus dem Praxistest bestätigt sich also.

(ref:mostDistantImagesSubCap) Bilder mit größtem Unterschied in DBSCAN und SLIC-Fit.

(ref:mostDistantImagesCap) Bilder mit größtem Unterschied in DBSCAN und SLIC-Fit. Links ist das Bild mit dem schlechtesten SLIC-Fit bei gleichzeitig bestem DBSCAN-Fit zu sehen, rechts umgekehrt.


```{r, echo = F}
dists <- df %>% 
  select(file, loss, analysis) %>% 
  pivot_wider(names_from =  analysis, values_from = loss) %>% 
  group_by(file) %>% 
  summarise(fit_diff = DBSCAN - SLIC) %>% 
  arrange(fit_diff)

images <- c(paste0('../../data/', dists$file[which.min(dists$fit_diff)], '.tif'),
                        paste0('../../data/', dists$file[which.max(dists$fit_diff)], '.tif'))
```

```{python, echo = F}
import cv2
import regex as re

def parsenumkey(key, path_to_image):
    with open(path_to_image, "rb") as f:
        for line in f:
            match = re.search(b"".join([b"^", key, b"=([-.0-9e]*)"]), line)
            if match is not None:
                break
    return float(match.group(1))

def import_image_wo_databar(path, compression = 4):
    image = cv2.imread(path, 0)
    dbheight = int(parsenumkey(b"DatabarHeight", path))
    image = image[: len(image) - dbheight]
    for i in range(compression):
        image = cv2.pyrDown(image)
    return(image)
  
for i,f in enumerate(r['images']):
  image = import_image_wo_databar(f, 0)
  _ = cv2.imwrite(f'../imgs/slic_dbscan_{i}.png', image)
```

```{r mostDistantImages, echo = F, fig.cap='(ref:mostDistantImagesCap)', fig.align='center',out.width=paste0(.96/2,'\\textwidth'), fig.show='hold', fig.scap='(ref:mostDistantImagesSubCap)'}
knitr::include_graphics(c('../imgs/slic_dbscan_0.png', 
                          '../imgs/slic_dbscan_1.png'), dpi = 300) 
```

Abschließend kann über den Versuch mithilfe von TPE-Optimierung die eingesetzten Analysen an die händische Linienschnitt-Auswertung anzupassen gesagt werden, dass zumindest für DBSCAN und SLIC eine Lösung möglich ist. Für Normalized Cuts nach SLIC muss festgestellt werden, dass zumindest mit dem gewählten Hyperparameter-Raum und der gewählten Optimierungsmethode kein wirklich verlässliches Ergebnis für die vorliegenden Bilder gefunden werden konnte.
Für SLIC und DBSCAN ist außerdem zu bemerken, dass die Verfahren bei unterschiedlichen Bildern unterschiedlich gut die per Linienschnitt gefundenen Kornverteilungen annähern. So ist beim Vergleich der Bilder mit dem größten Unterschied im Verteilungsabstand exemplarisch zu sehen, dass DBSCAN besser bei unregelmäßigen Korngrößen abschneidet, SLIC bei regelmäßigen, kleinen Körnern aber die Nase vorn hat.




